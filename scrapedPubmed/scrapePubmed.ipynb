{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713e5851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from os.path import exists\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5130614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e1702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# treat empty strings and np.nan as NAm will impact dropna method\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "# set Jupyter to display all output from a cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "MAX_USER_PROFILES = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264e62b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_num_citations(url):\n",
    "    time.sleep(1)\n",
    "    page = requests.get(url)\n",
    "    # Create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "    relevant_cited_by_div = soup.find(class_='citedby-articles')\n",
    "    \n",
    "    if not relevant_cited_by_div:\n",
    "        # done with page\n",
    "        return 0\n",
    "    \n",
    "    relevant_amount_html = relevant_cited_by_div.find(class_='amount')\n",
    "    for amount in relevant_amount_html:\n",
    "        break\n",
    "\n",
    "    return int(amount.replace(',', '').replace(' ', ''))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aede8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_pubmed_results_page(query, pageno=0, ranking=0):\n",
    "    pubmed_articles = []\n",
    "\n",
    "    url = f'https://pubmed.ncbi.nlm.nih.gov/?term={query}&filter=pubt.clinicalconference&filter=pubt.clinicalstudy&filter=pubt.clinicaltrial&filter=pubt.clinicaltrialprotocol&filter=pubt.clinicaltrialphasei&filter=pubt.clinicaltrialphaseii&filter=pubt.clinicaltrialphaseiii&filter=pubt.clinicaltrialphaseiv&filter=pubt.comparativestudy&filter=pubt.controlledclinicaltrial&filter=pubt.editorial&filter=pubt.meta-analysis&filter=pubt.observationalstudy&filter=pubt.practiceguideline&filter=pubt.pragmaticclinicaltrial&filter=pubt.randomizedcontrolledtrial&filter=pubt.researchsupportamericanrecoveryandreinvestmentact&filter=pubt.researchsupportnihextramural&filter=pubt.researchsupportnihintramural&filter=pubt.researchsupportnonusgovt&filter=pubt.researchsupportusgovtnonphs&filter=pubt.researchsupportusgovtphs&filter=pubt.researchsupportusgovernment&filter=pubt.validationstudy&show_snippets=off&size=200&page={pageno}&format=pubmed'\n",
    "    print(f'\\npage={pageno},url={url}')\n",
    "    #print(f'page={pageno}')\n",
    "    time.sleep(1)\n",
    "    page = requests.get(url)\n",
    "\n",
    "    # Create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    # Pull all text from the BodyText div\n",
    "    relevant_pubmed_html = soup.find(class_='search-results-chunk')\n",
    "    #print(relevant_pubmed_html)\n",
    "\n",
    "    if not relevant_pubmed_html:\n",
    "        # done with all pages\n",
    "        return (pubmed_articles, ranking)\n",
    "\n",
    "    for pubmed_results in relevant_pubmed_html:\n",
    "        # fetch the data inside the HTML element\n",
    "        break\n",
    "    \n",
    "    lines = pubmed_results.split('\\r\\n')\n",
    "    #print(f'lines_length={len(lines)}')\n",
    "\n",
    "    article = None\n",
    "    current_tag = ''\n",
    "\n",
    "    try:\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "\n",
    "            if line == '':\n",
    "                if article:\n",
    "                    if len(article['authors']) > 1:\n",
    "                        if article['authors'][-1]['affiliations'] == '':\n",
    "                            article['authors'][-1]['affiliations'] = article['authors'][-2]['affiliations']\n",
    "\n",
    "                    for idx, author in enumerate(article['authors']):\n",
    "                        article['authors'][idx]['affiliations'] = article['authors'][idx]['affiliations'].split(';')\n",
    "                        article['authors'][idx]['affiliations'] = [aff.strip() for aff in article['authors'][idx]['affiliations'] if aff != '']\n",
    "                    article['citations'] = 0#fetch_num_citations(article['url'])\n",
    "                    pubmed_articles.append(article)\n",
    "                    article = None\n",
    "                current_tag = 'new'\n",
    "            elif re.search(r'^PMID', line):\n",
    "                ranking += 1\n",
    "                article = {\n",
    "                    'pmid':'', \n",
    "                    'pmc':'', \n",
    "                    'url':'', \n",
    "                    'title':'', \n",
    "                    'published_date':'', \n",
    "                    'abstract':'', \n",
    "                    'reference':'', \n",
    "                    'article_type':[], \n",
    "                    'authors':[], \n",
    "                    'journal':'', \n",
    "                    'mesh_terms':[], \n",
    "                    'citations': 0, \n",
    "                    'rank': ranking\n",
    "                }\n",
    "                article['pmid'] = re.sub(r'^PMID\\s*\\-\\s+', '', line).strip()\n",
    "                article['url'] = f'https://pubmed.ncbi.nlm.nih.gov/{article[\"pmid\"]}/'\n",
    "                current_tag = 'pmid'\n",
    "            elif re.search(r'^PMC\\s+\\-\\s+', line):\n",
    "                article['pmc'] = re.sub(r'^PMC\\s+\\-\\s+', '', line).strip()\n",
    "                current_tag = 'pmc'\n",
    "            elif re.search(r'^TI\\s+\\-\\s+', line):\n",
    "                article['title'] = re.sub(r'^TI\\s+\\-\\s+', '', line).strip()\n",
    "                current_tag = 'title'\n",
    "            elif re.search(r'^DP\\s+\\-\\s+', line):\n",
    "                article['published_date'] = re.sub(r'^DP\\s+\\-\\s+', '', line).strip()\n",
    "                current_tag = 'published_date'\n",
    "            elif re.search(r'^SO\\s+\\-\\s+', line):\n",
    "                article['reference'] = re.sub(r'^SO\\s+\\-\\s+', '', line).strip()\n",
    "                current_tag = 'reference'\n",
    "            elif re.search(r'^AB\\s+\\-\\s+', line):\n",
    "                article['abstract'] = re.sub(r'^AB\\s+\\-\\s+', '', line).strip()\n",
    "                current_tag = 'abstract'\n",
    "            elif re.search(r'^MHDA\\s*\\-\\s*', line):\n",
    "                # ignore and skip it\n",
    "                current_tag = ''\n",
    "                continue\n",
    "            elif re.search(r'^MH\\s+\\-\\s+', line):\n",
    "                mesh_term = re.sub(r'^MH\\s+\\-\\s+', '', line).strip()\n",
    "                mesh_term = re.sub(r'\\*', '', mesh_term).strip()\n",
    "                article['mesh_terms'].append(mesh_term)\n",
    "                current_tag = 'mesh_terms'\n",
    "            elif re.search(r'^PT\\s+\\-\\s+', line):\n",
    "                article['article_type'].append(re.sub(r'^PT\\s+\\-\\s+', '', line).strip())\n",
    "                current_tag = 'article_type'\n",
    "            elif re.search(r'^JT\\s+\\-\\s+', line):\n",
    "                article['journal'] = re.sub(r'^JT\\s+\\-\\s+', '', line).strip()\n",
    "                current_tag = 'journal'\n",
    "            elif re.search(r'^FAU\\s+\\-\\s+', line):\n",
    "                if len(article['authors']) > 1:\n",
    "                    if article['authors'][-1]['affiliations'] == '':\n",
    "                        article['authors'][-1]['affiliations'] = article['authors'][-2]['affiliations']\n",
    "                article['authors'].append({\n",
    "                    'full_name':re.sub(r'^FAU\\s+\\-\\s+', '', line).strip(), \n",
    "                    'initial_name':'', \n",
    "                    'affiliations':''\n",
    "                })\n",
    "                current_tag = 'full_name'\n",
    "            elif re.search(r'^AU\\s+\\-\\s+', line):\n",
    "                article['authors'][-1]['initial_name'] = re.sub(r'^AU\\s+\\-\\s+', '', line).strip()\n",
    "                current_tag = 'initial_name'\n",
    "            elif re.search(r'^AD\\s+\\-\\s+', line):\n",
    "                if current_tag == 'affiliations':\n",
    "                    article['authors'][-1]['affiliations'] += ';'\n",
    "                    article['authors'][-1]['affiliations'] += re.sub(r'^AD\\s+\\-\\s+', '', line).strip()\n",
    "                else:\n",
    "                    if len(article['authors']) == 0:\n",
    "                        # seems like we arrived at AD without FAU, so assume no author but no name\n",
    "                        article['authors'].append({\n",
    "                            'full_name':'', \n",
    "                            'initial_name':'', \n",
    "                            'affiliations':''\n",
    "                        })\n",
    "                    #print('1\\t', article['authors'][-1]['affiliations'])\n",
    "                    article['authors'][-1]['affiliations'] = re.sub(r'^AD\\s*\\-\\s*', '', line).strip()\n",
    "                    #print('2\\t', article['authors'][-1]['affiliations'])\n",
    "                    current_tag = 'affiliations'\n",
    "            elif re.search(r'^[A-Z]+\\s*\\-\\s+', line):\n",
    "                # some tag that we don't care about so ignore,  and move on\n",
    "                current_tag = ''\n",
    "                continue\n",
    "            elif current_tag == 'title':\n",
    "                article['title'] += ' '\n",
    "                article['title'] += re.sub(r'^TI\\s+\\-\\s+', '', line).strip()\n",
    "            elif current_tag == 'abstract':\n",
    "                article['abstract'] += ' '\n",
    "                article['abstract'] += re.sub(r'^AB\\s+\\-\\s+', '', line).strip()\n",
    "                #article['abstract'] = re.sub(r'^BACKGROUND:\\s*', '', article['abstract']).strip()\n",
    "            elif current_tag == 'key_phrases':\n",
    "                key_phrase = re.sub(r'^MH\\s+\\-\\s+', '', line).strip()\n",
    "                key_phrase = re.sub(r'\\*', '', key_phrase).strip()\n",
    "                article['key_phrases'].append(key_phrase)\n",
    "            elif current_tag == 'article_type':\n",
    "                article['article_type'].append(re.sub(r'^PT\\s+\\-\\s+', '', line).strip())\n",
    "            elif current_tag == 'affiliations':\n",
    "                article['authors'][-1]['affiliations'] += ' '\n",
    "                article['authors'][-1]['affiliations'] += re.sub(r'^AD\\s+\\-\\s+', '', line).strip()\n",
    "    except Exception as inst:\n",
    "        print(f'\\tEXCEPTION: {line}')\n",
    "        print(inst)\n",
    "        print(type(inst))    # the exception instance\n",
    "        print(inst.args)     # arguments stored in .args\n",
    "        #raise inst\n",
    "        pass\n",
    "    \n",
    "    return (pubmed_articles, ranking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5350106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_term_mapping():\n",
    "    with open('who_search_terms_mapping.pkl', 'rb') as handle:\n",
    "        out_search_space = pickle.load(handle)\n",
    "        return out_search_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e2f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = get_search_term_mapping()\n",
    "for key in search_space:\n",
    "    vals = search_space[key]\n",
    "    vals = [re.sub(r'\\s*,\\s*|\\s*&\\s*', ' ', val) for val in vals]\n",
    "    vals = [re.sub(r'\\s+', '+', val) for val in vals]\n",
    "    key = re.sub(r'\\s*,\\s*|\\s*&\\s*', ' ', key)\n",
    "    key = re.sub(r'\\s+', '+', key)\n",
    "    print(key, '--->', vals)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaf143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = get_search_term_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330e3f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a457be",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = 'AD  - Writing Committee J Skinner East Anglia region; MP Maslanyj; TJ Mee and SG Allen'\n",
    "re.sub(r'^AD\\s*\\-\\s*', '', line).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df740de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "query = 'central+nervous+system+tumours'\n",
    "pageno=1\n",
    "url = f'https://pubmed.ncbi.nlm.nih.gov/?term={query}&filter=pubt.clinicalconference&filter=pubt.clinicalstudy&filter=pubt.clinicaltrial&filter=pubt.clinicaltrialprotocol&filter=pubt.clinicaltrialphasei&filter=pubt.clinicaltrialphaseii&filter=pubt.clinicaltrialphaseiii&filter=pubt.clinicaltrialphaseiv&filter=pubt.comparativestudy&filter=pubt.controlledclinicaltrial&filter=pubt.editorial&filter=pubt.meta-analysis&filter=pubt.observationalstudy&filter=pubt.practiceguideline&filter=pubt.pragmaticclinicaltrial&filter=pubt.randomizedcontrolledtrial&filter=pubt.researchsupportamericanrecoveryandreinvestmentact&filter=pubt.researchsupportnihextramural&filter=pubt.researchsupportnihintramural&filter=pubt.researchsupportnonusgovt&filter=pubt.researchsupportusgovtnonphs&filter=pubt.researchsupportusgovtphs&filter=pubt.researchsupportusgovernment&filter=pubt.validationstudy&show_snippets=off&size=200&page={pageno}&format=pubmed'\n",
    "url\n",
    "#scrape_pubmed_results(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f91e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "query = 'central+nervous+system+tumours'\n",
    "pageno = 10\n",
    "ranking = 0\n",
    "\n",
    "all_pubmed_articles = []\n",
    "while(True):\n",
    "    pageno += 1\n",
    "    \n",
    "    pubmed_articles, ranking = scrape_pubmed_results_page(query, pageno, ranking)\n",
    "    print(f'\\tpage={pageno}, ranking={ranking}, length={len(pubmed_articles)}')\n",
    "    \n",
    "    #break\n",
    "    if len(pubmed_articles) == 0:\n",
    "        break\n",
    "    all_pubmed_articles.extend(pubmed_articles)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10df1f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_pubmed_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31871442",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pubmed_articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532a8b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec7e1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9561b9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
